{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "from library import Map, GradientDescent\n",
    "import time\n",
    "from random import randrange\n",
    "import scipy.spatial.distance as d\n",
    "import heapq as hq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yq/gyf11wn125qgkzlcv24mbp3w0000gn/T/ipykernel_88117/3992257774.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset.replace(to_replace=(\"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"), value=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "'''Downloading dataset'''\n",
    "dataset = pd.read_csv(\"/Users/alessandrococcia/Downloads/ObesityDataSet.csv\")\n",
    "\n",
    "'''Dataset sampling'''\n",
    "dataset = dataset.sample(frac=1, ignore_index=True) #shuffle sample in the training set\n",
    "\n",
    "'''mapping delle stringhe'''\n",
    "dataset.replace(to_replace=(\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\"), value=0, inplace=True)\n",
    "dataset.replace(to_replace=(\"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"), value=1, inplace=True)\n",
    "dataset = pd.get_dummies(dataset, drop_first=True, dtype=float)\n",
    "\n",
    "'''normalization'''\n",
    "dataset = (dataset-dataset.mean())/dataset.std()\n",
    "\n",
    "'''Inserimento colonna di bias'''\n",
    "dataset.insert(0, \"Bias\", np.ones(len(dataset)), True) #Bias row\n",
    "\n",
    "\n",
    "TRAIN_TEST_SPLIT_PERCENTAGE = 0.9\n",
    "dataset_training = dataset[:int(len(dataset) * TRAIN_TEST_SPLIT_PERCENTAGE)]\n",
    "dataset_test = dataset[int(len(dataset) * TRAIN_TEST_SPLIT_PERCENTAGE):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[1;32m     13\u001b[0m neigh \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m---> 14\u001b[0m neigh \u001b[38;5;241m=\u001b[39m \u001b[43mneigh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m x_test \u001b[38;5;241m=\u001b[39m dataset_training\u001b[38;5;241m.\u001b[39mloc[:, dataset_training\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNObeyesdad\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m sk_prediction  \u001b[38;5;241m=\u001b[39m neigh\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# KNeighborsClassifier.metric is not validated yet\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    219\u001b[0m )\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m        The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neighbors/_base.py:500\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# Using `dtype=np.intp` is necessary since `np.bincount`\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# (called in _classification.py) fails when dealing\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# with a float64 array on 32bit systems.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/multiclass.py:221\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    213\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m ]:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "features_len = len(dataset_test.columns)\n",
    "len_test = len(dataset_test)\n",
    "column_output_index = dataset_test.columns.get_loc(\"NObeyesdad\")\n",
    "\n",
    "count = 0\n",
    "k = 1\n",
    "\n",
    "X = dataset_training.loc[:, dataset_training.columns != 'NObeyesdad']\n",
    "Y = dataset_training.loc[:, dataset_training.columns == 'NObeyesdad']\n",
    "Z = dataset_test.loc[:, dataset_test.columns != 'NObeyesdad']\n",
    "\n",
    "\n",
    "for j in range(1899, len_test+1899):\n",
    "    minimum = math.inf\n",
    "    ret = None\n",
    "    sample = dataset_test.loc[j:j]\n",
    "    '''initializing minheap for knn'''\n",
    "    minheap = []\n",
    "    hq.heapify(minheap)\n",
    "    for i in range(0, len(dataset_training)):\n",
    "        x = dataset.loc[i:i]\n",
    "        distance = d.minkowski(np.array(sample)[0], np.array(x)[0], features_len)\n",
    "        hq.heappush(minheap, (distance, list(x[\"NObeyesdad\"])))\n",
    "        if distance < minimum:\n",
    "            minimum = distance\n",
    "            ret = x[\"NObeyesdad\"]\n",
    "    \n",
    "    '''ksmallest'''\n",
    "    ksmallest = hq.nsmallest(k, minheap)\n",
    "    max_value = max(list(zip(*ksmallest))[1])\n",
    "    if max_value == np.array(ret):\n",
    "        count += 1\n",
    "\n",
    "print(count/len(dataset_test))\n",
    "\n",
    "\n",
    "'''sklearn'''\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "neigh = neigh.fit(X,Y)\n",
    "x_test = dataset_training.loc[:, dataset_training.columns != 'NObeyesdad']\n",
    "sk_prediction  = neigh.predict(x_test)\n",
    "print(sk_prediction)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
