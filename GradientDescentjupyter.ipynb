{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94ea7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "from library import Map, GradientDescent\n",
    "import time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from random import randrange\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a9d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Downloading dataset'''\n",
    "dataset = pd.read_csv(\"/Users/alessandrococcia/Downloads/ObesityDataSet.csv\")\n",
    "\n",
    "'''Dataset sampling'''\n",
    "dataset.sample(frac=1, ignore_index=True) #shuffle sample in the training set\n",
    "\n",
    "'''mapping delle stringhe'''\n",
    "\n",
    "dataset = pd.get_dummies(dataset, drop_first=True, dtype=float)\n",
    "\n",
    "'''normalization'''\n",
    "#dataset = (dataset-dataset.min())/(dataset.max()-dataset.min())\n",
    "dataset =(dataset-dataset.mean())/dataset.std()\n",
    "\n",
    "'''Inserimento colonna di bias'''\n",
    "dataset.insert(0, \"Bias\", np.ones(len(dataset)), True) #Bias row\n",
    "\n",
    "TRAIN_TEST_SPLIT_PERCENTAGE = 0.9\n",
    "dataset_training = dataset[:int(len(dataset) * TRAIN_TEST_SPLIT_PERCENTAGE)]\n",
    "dataset_test = dataset[int(len(dataset) * TRAIN_TEST_SPLIT_PERCENTAGE):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32a522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Map:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.count_dataset = {}\n",
    "        self.d = {}\n",
    "        self.dataset_dictionary = {}\n",
    "        self.matrice = None\n",
    "        self.dataset = None\n",
    "        len = None\n",
    "    \n",
    "    def mappingElement(self, string):\n",
    "        if type(string) is str:\n",
    "            if self.d.get(string) is not None:\n",
    "                return self.d.get(string)\n",
    "            else:\n",
    "                self.count = self.count+1\n",
    "                self.d[string] = self.count\n",
    "                return self.count\n",
    "        return float(string)\n",
    "    \n",
    "    def mappingMatrix(self, matrice):\n",
    "        self.matrice = None\n",
    "        self.matrice = np.array(matrice)\n",
    "        len = self.matrice.shape\n",
    "        for g in range(len[0]):\n",
    "            for j in range(len[1]):\n",
    "                self.matrice[g][j] = self.mappingElement(self.matrice[g][j])\n",
    "        return np.float64(self.matrice.copy())\n",
    "    \n",
    "    def mappingElementDataset(self, value, colonna):\n",
    "        if type(value) is str:\n",
    "            if self.dataset_dictionary[colonna].get(value) is not None:\n",
    "                return self.dataset_dictionary[colonna].get(value)\n",
    "            else:\n",
    "                if self.count_dataset.get(colonna) is None:\n",
    "                    self.count_dataset[colonna] = 0\n",
    "                    self.dataset_dictionary[colonna][value] = self.count_dataset[colonna]\n",
    "                    return self.count_dataset[colonna]\n",
    "                self.count_dataset[colonna] += 1\n",
    "                self.dataset_dictionary[colonna][value] = self.count_dataset[colonna]\n",
    "                return self.count_dataset[colonna]\n",
    "        return value\n",
    "    \n",
    "    def mappingDataset(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        colonne = dataset.columns\n",
    "        length = len(dataset)\n",
    "        for column in colonne:\n",
    "            self.dataset_dictionary[column] = {}\n",
    "            for index in range(length):\n",
    "                dataset.at[index, column] = self.mappingElementDataset(dataset.at[index, column], column)\n",
    "        return self.dataset\n",
    "\n",
    "    def MSE(self, a, b):\n",
    "        return np.mean((np.square(a - b)))\n",
    "    def RMSE(self, a, b):\n",
    "        return math.sqrt(np.mean(np.square(a - b)))\n",
    "    def MAE(self, a, b):\n",
    "        return np.mean(abs(a-b))\n",
    "    \n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, outputstring, positive, negative): \n",
    "        self.outputstring = outputstring\n",
    "        self.positive = positive\n",
    "        self.negative = negative\n",
    "        self.nodes = []\n",
    "        self.label = None\n",
    "        self.root = False\n",
    "\n",
    "    def LearnDecisionTree(self, examples, attributes, parent_examples, column_values):\n",
    "        self.root = True\n",
    "        self.LearnDecisionTreeAux_(examples, attributes, parent_examples, column_values)\n",
    "\n",
    "    def LearnDecisionTreeAux_(self, examples, attributes, parent_examples, column_values):\n",
    "        same_classification = self.SameClassification(examples)    \n",
    "        \n",
    "        if len(examples.loc[:, examples.columns != self.outputstring]) == 0:\n",
    "            return self.PluralityValue(parent_examples)\n",
    "        elif same_classification is not False:\n",
    "            return same_classification\n",
    "        elif len(attributes) == 0: \n",
    "            return self.PluralityValue(examples)\n",
    "        else:\n",
    "            '''Seleziono l'attributo migliore'''\n",
    "            bestattribute = self.Importance(attributes, examples)\n",
    "            self.label = bestattribute #Seleziono l'attributo migliore\n",
    "            \n",
    "            for value in self.Values1(bestattribute, column_values):\n",
    "                remainingexamples = self.Examples(bestattribute, examples, value)\n",
    "                tree = DecisionTree(self.outputstring, self.positive, self.negative)\n",
    "                attributes_left = self.PopListValue(attributes.copy(), bestattribute)                \n",
    "                subtree = tree.LearnDecisionTreeAux_(remainingexamples.loc[:, remainingexamples.columns != bestattribute], attributes_left, examples, column_values)\n",
    "                self.nodes.append((value, subtree))\n",
    "        return self\n",
    "        \n",
    "    def Importance(self, attributes, examples): \n",
    "        max = -1\n",
    "        ret = None\n",
    "        for a in attributes:\n",
    "            loc = self.Gain(examples, a)\n",
    "            if loc > max:\n",
    "                max = loc\n",
    "                ret = a\n",
    "        return ret\n",
    "        \n",
    "    def B(self, q):\n",
    "        if q == 1 or q == 0:\n",
    "            return 0\n",
    "        return -(q*math.log2(q)+(1-q)*math.log2(1-q))\n",
    "    \n",
    "    def Remainder(self, examples, attribute, p, n):\n",
    "        sum = 0\n",
    "        for v in self.Values2(attribute, examples):\n",
    "            if type(v) is not str and math.isnan(float(v)):\n",
    "                pk = len(examples.loc[(examples[self.outputstring] == self.positive) & (examples[attribute].isnull())])\n",
    "                nk = len(examples.loc[(examples[self.outputstring] == self.negative) & (examples[attribute].isnull())])\n",
    "            else:\n",
    "                pk = len(examples.loc[(examples[self.outputstring] == self.positive) & (examples[attribute] == v)])\n",
    "                nk = len(examples.loc[(examples[self.outputstring] == self.negative) & ((examples[attribute] == v))])\n",
    "            \n",
    "            partial = (pk+nk)*self.B(pk/(pk+nk))\n",
    "            sum += partial\n",
    "        return (1/(p+n))*sum\n",
    "    \n",
    "    def Gain(self, examples, attribute):\n",
    "        p = len(examples.loc[examples[self.outputstring] == self.positive])\n",
    "        n = len(examples.loc[examples[self.outputstring] == self.negative])\n",
    "        b = self.B(p/(p+n))\n",
    "        r = self.Remainder(examples, attribute, p, n)\n",
    "        return (b-r)\n",
    "        \n",
    "    def PluralityValue(self, parent_examples): \n",
    "        '''Selects the most common ouput value among a set of examples, breaking ties randomly'''\n",
    "        value, max = [], 0\n",
    "        d = self.CreateDictionary(parent_examples)\n",
    "        for key in d.keys():\n",
    "            if d.get(key) > max:\n",
    "                max = d.get(key)\n",
    "                value = []\n",
    "                value.append(key)\n",
    "            elif d.get(key) == max:\n",
    "                '''se ci sono più massimi li metto tutti in una lista dalla quale ne\n",
    "                    selezionerò uno randomicamente\n",
    "                '''\n",
    "                value.append(key)\n",
    "        return rn.choice(value)\n",
    "        \n",
    "    def SameClassification(self, examples): \n",
    "        if (len(examples) == 0):\n",
    "            return False\n",
    "        d = self.CreateDictionary(examples)\n",
    "        if (len(d.keys()) == 1):\n",
    "            return list(d.keys())[0]\n",
    "        return False\n",
    "    def CreateDictionary(self, examples):\n",
    "        examples = examples[self.outputstring].tolist()\n",
    "        d = {}\n",
    "        for i in range(len(examples)):\n",
    "            if d.get(examples[i]) is None:\n",
    "                d[examples[i]] = 1\n",
    "            else:\n",
    "                d[examples[i]] += 1\n",
    "        return d\n",
    "\n",
    "    def Values1(self, attribute, dictionary): \n",
    "        return list(dictionary.get(attribute))\n",
    "    \n",
    "    def Values2(self, attribute, examples):\n",
    "        return examples[attribute].unique()\n",
    "\n",
    "    def Examples(self, attribute, examples, value):\n",
    "        exs = examples.loc[examples[attribute] == value]\n",
    "        return exs\n",
    "    def PopListValue(self, lista, value):\n",
    "        if value not in lista:\n",
    "            return None\n",
    "        lista.remove(value)\n",
    "        return lista \n",
    "    def PrintDecisionTree(self, count):\n",
    "        print(\" \"*count, self.label)\n",
    "        for elem in self.nodes:\n",
    "            if type(elem[1]) is not DecisionTree:\n",
    "                print(\"    \"*(count+1), elem[0], \" --> \", elem[1])\n",
    "            else:\n",
    "                elem[1].PrintDecisionTree(count+1)\n",
    "\n",
    "    def Prediction(self, input):\n",
    "        for i in range(len(self.nodes)):\n",
    "            x = input[self.label].values[0]\n",
    "            if type(self.nodes[i][0]) is not str and math.isnan(float(self.nodes[i][0])):\n",
    "                if type(x) is not str and math.isnan(float(x)):\n",
    "                    if type(self.nodes[i][1]) is DecisionTree:\n",
    "                        return self.nodes[i][1].Prediction(input)\n",
    "                    return self.nodes[i][1]\n",
    "            elif self.nodes[i][0] == x:\n",
    "                if type(self.nodes[i][1]) is DecisionTree:\n",
    "                    return self.nodes[i][1].Prediction(input)\n",
    "                return self.nodes[i][1]\n",
    "        return None\n",
    "\n",
    "class GradientDescent:\n",
    "    def __init__(self, learningrate, epochs, parameters_length, output_string, batch_size): \n",
    "        self.learningrate = learningrate\n",
    "        self.epochs = epochs\n",
    "        self.parameters_length = parameters_length\n",
    "        self.parameters = None\n",
    "        self.output_string = output_string\n",
    "        self.len_totale = None\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def SGD(self, training_set):\n",
    "        \n",
    "        '''Inizializzo i pesi ad 1'''\n",
    "        self.parameters = np.ones(self.parameters_length)\n",
    "        '''Su input e output totale calcolerò ad ogni n-esima epoca l'errore'''\n",
    "        input_totale = training_set.loc[:len(training_set), training_set.columns != self.output_string]\n",
    "        output_totale = training_set.loc[:len(training_set), training_set.columns == self.output_string]\n",
    "        self.len_totale = len(training_set)\n",
    "\n",
    "        '''ciclo for per le epoche'''\n",
    "        '''Batch == input totale: non devo randomizzare'''\n",
    "        if self.batch_size == self.len_totale:\n",
    "            input = input_totale\n",
    "            output = output_totale\n",
    "            for i in range(self.epochs):\n",
    "                gradient = self.gradient(input, output)\n",
    "                self.SGD_aux(gradient)\n",
    "                if (not (i%10000)):\n",
    "                    print(\"Epoca: \\t\", i)\n",
    "                    print(\"MSE: \", self.MSE(self.prediction(input_totale), output_totale))\n",
    "        \n",
    "        else:\n",
    "            '''uso delle minibatch che devono avere i sample randomizzati ad ogni iterazione'''\n",
    "            for i in range(self.epochs):\n",
    "                batch = training_set.sample(n=self.batch_size)\n",
    "                input = batch.loc[:, training_set.columns != self.output_string]\n",
    "                output = batch.loc[:, training_set.columns == self.output_string]\n",
    "                gradient = self.gradient(input, output)\n",
    "                self.SGD_aux(gradient)\n",
    "                \n",
    "                if (not (i%10000)):\n",
    "                    print(\"Epoca: \\t\", i)\n",
    "                    print(\"MSE: \", self.MSE(self.prediction(input_totale), output_totale))\n",
    "                \n",
    "        return self.parameters\n",
    "\n",
    "    def SGD_aux(self, gradient):\n",
    "        self.parameters -= self.learningrate*gradient\n",
    "\n",
    "    def gradient(self, input, output): \n",
    "        output = np.array(output).T\n",
    "        prediction = self.prediction(input)\n",
    "        error = prediction - output\n",
    "        return np.matmul(error, input)\n",
    "\n",
    "    def prediction(self, input):\n",
    "        return np.dot(input, self.parameters)\n",
    "\n",
    "    def MSE(self, prediction, output):\n",
    "        output = np.array(output)\n",
    "        return np.mean((output - prediction)**2)\n",
    "    def RMSE(self, prediction, output):\n",
    "        return math.sqrt(np.mean((output - prediction)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fa37c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: \t 0\n",
      "MSE:  24.64514178309623\n",
      "Epoca: \t 10000\n",
      "MSE:  1.7846712462168153\n",
      "Epoca: \t 20000\n",
      "MSE:  1.7210601241321803\n",
      "Epoca: \t 30000\n",
      "MSE:  1.707410737311722\n",
      "Epoca: \t 40000\n",
      "MSE:  1.7116694930861778\n",
      "Epoca: \t 50000\n",
      "MSE:  1.6984440438089992\n",
      "Epoca: \t 60000\n",
      "MSE:  1.6914073866750585\n",
      "58.27085518836975 [ 8.53110778e-03 -1.21187547e-02  3.17042161e-01  6.46144282e-03\n",
      " -1.38957745e-02  4.03215871e-03  3.69772533e-04  4.59043057e-03\n",
      "  9.70832699e-03 -1.54346309e-02 -5.89679692e-03  2.74287995e-02\n",
      " -6.69868473e-03 -8.34284738e-04  3.76998196e-03  3.88452925e-03\n",
      "  3.87745863e-01  1.05098584e+00  9.99978617e-01 -1.24886622e-02\n",
      " -2.67415894e-03 -1.42466944e-02 -2.11525100e-03  1.83733661e-01\n",
      "  6.20307119e-01  7.81983556e-01  1.00392616e+00  3.32767578e-01\n",
      "  4.18182923e-01]\n"
     ]
    }
   ],
   "source": [
    "gd = GradientDescent(1e-3, 70000, dataset_training.shape[1]-1, 'Weight', 1)\n",
    "\n",
    "start = time.time()\n",
    "pesi = gd.SGD(dataset_training)\n",
    "end = time.time()\n",
    "print(end-start, pesi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21aa53e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.13812554467754154\n",
      "RMSE:  0.3716524514617676\n",
      "MAE:  0.3249197904591904\n",
      "MSE_sklearn:  0.377664398692556\n",
      "RMSE_sklearn:  0.6145440575683374\n",
      "MAE_sklearn:  0.5249601168214079\n",
      "MSE_sklearn SGD:  0.14643371987563464\n",
      "RMSE_sklearn SGD:  0.38266659101054884\n",
      "MAE_sklearn SGD:  0.3353679576421768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(dataset_test.loc[:, dataset_test.columns != 'Weight'])\n",
    "Y_effettivo = np.array(dataset_test['Weight'])\n",
    "Y_predetto = np.array(np.matmul(X_test, pesi))\n",
    "\n",
    "\n",
    "\n",
    "map = Map()\n",
    "print(\"MSE: \", map.MSE(Y_effettivo, Y_predetto))\n",
    "print(\"RMSE: \", map.RMSE(Y_effettivo, Y_predetto))\n",
    "print(\"MAE: \", map.MAE(Y_effettivo, Y_predetto))\n",
    "\n",
    "'''sklearn'''\n",
    "\n",
    "X = np.array(dataset_training.loc[:, dataset_training.columns != 'Weight'])\n",
    "Y = np.array(dataset_training.loc[:, dataset_training.columns == 'Weight'])\n",
    "\n",
    "reg = LinearRegression().fit(X, Y)\n",
    "scikit_predict = np.array(reg.predict(X_test))\n",
    "\n",
    "print(\"MSE_sklearn: \", map.MSE(Y_effettivo, scikit_predict))\n",
    "print(\"RMSE_sklearn: \", map.RMSE(Y_effettivo, scikit_predict))\n",
    "print(\"MAE_sklearn: \", map.MAE(Y_effettivo, scikit_predict))\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# X_test e Y_effettivo sono i dati di test\n",
    "\n",
    "# Definisci il regressore SGD\n",
    "sgd_regressor = SGDRegressor(max_iter=100000000, alpha=0.001, random_state=42)\n",
    "\n",
    "# Addestra il modello\n",
    "sgd_regressor.fit(X, Y)\n",
    "\n",
    "# Effettua previsioni\n",
    "Y_predetto_sgd = np.array(sgd_regressor.predict(X_test))\n",
    "\n",
    "# Calcola le metriche di valutazione\n",
    "\n",
    "# Stampare le metriche di valutazione\n",
    "print(\"MSE_sklearn SGD: \", map.MSE(Y_effettivo, Y_predetto_sgd))\n",
    "print(\"RMSE_sklearn SGD: \", map.RMSE(Y_effettivo, Y_predetto_sgd))\n",
    "print(\"MAE_sklearn SGD: \", map.MAE(Y_effettivo, Y_predetto_sgd))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
