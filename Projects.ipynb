{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d94ea7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "from library import Map, GradientDescent\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from random import randrange\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Downloading dataset'''\n",
    "dataset = pd.read_csv(\"/Users/alessandrococcia/Downloads/ObesityDataSet.csv\")\n",
    "#dataset = dataset.sample(frac=1) #shuffle sample in the training set\n",
    "\n",
    "'''mapping delle stringhe'''\n",
    "#m = Map()\n",
    "#dataset = m.mappingDataset(dataset)\n",
    "dataset = pd.get_dummies(dataset).astype(float)\n",
    "\n",
    "'''normalization'''\n",
    "dataset = (dataset-dataset.min())/(dataset.max()-dataset.min())\n",
    "\n",
    "'''Inserimento colonna di bias'''\n",
    "dataset.insert(0, \"Bias\", np.ones(len(dataset)), True) #Bias row\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "TRAIN_TEST_SPLIT_PERCENTAGE = 0.9\n",
    "dataset_training = dataset[:int(len(dataset) * TRAIN_TEST_SPLIT_PERCENTAGE)]\n",
    "dataset_test = dataset[int(len(dataset) * TRAIN_TEST_SPLIT_PERCENTAGE):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b32a522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Map:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.count_dataset = {}\n",
    "        self.d = {}\n",
    "        self.dataset_dictionary = {}\n",
    "        self.matrice = None\n",
    "        self.dataset = None\n",
    "        len = None\n",
    "    \n",
    "    def mappingElement(self, string):\n",
    "        if type(string) is str:\n",
    "            if self.d.get(string) is not None:\n",
    "                return self.d.get(string)\n",
    "            else:\n",
    "                self.count = self.count+1\n",
    "                self.d[string] = self.count\n",
    "                return self.count\n",
    "        return float(string)\n",
    "    \n",
    "    def mappingMatrix(self, matrice):\n",
    "        self.matrice = None\n",
    "        self.matrice = np.array(matrice)\n",
    "        len = self.matrice.shape\n",
    "        for g in range(len[0]):\n",
    "            for j in range(len[1]):\n",
    "                self.matrice[g][j] = self.mappingElement(self.matrice[g][j])\n",
    "        return np.float64(self.matrice.copy())\n",
    "    \n",
    "    def mappingElementDataset(self, value, colonna):\n",
    "        if type(value) is str:\n",
    "            if self.dataset_dictionary[colonna].get(value) is not None:\n",
    "                return self.dataset_dictionary[colonna].get(value)\n",
    "            else:\n",
    "                if self.count_dataset.get(colonna) is None:\n",
    "                    self.count_dataset[colonna] = 0\n",
    "                    self.dataset_dictionary[colonna][value] = self.count_dataset[colonna]\n",
    "                    return self.count_dataset[colonna]\n",
    "                self.count_dataset[colonna] += 1\n",
    "                self.dataset_dictionary[colonna][value] = self.count_dataset[colonna]\n",
    "                return self.count_dataset[colonna]\n",
    "        return value\n",
    "    \n",
    "    def mappingDataset(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        colonne = dataset.columns\n",
    "        length = len(dataset)\n",
    "        for column in colonne:\n",
    "            self.dataset_dictionary[column] = {}\n",
    "            for index in range(length):\n",
    "                dataset.at[index, column] = self.mappingElementDataset(dataset.at[index, column], column)\n",
    "        return self.dataset\n",
    "\n",
    "    def MSE(self, a, b):\n",
    "        return np.mean((np.square(a - b)))\n",
    "    def RMSE(self, a, b):\n",
    "        return math.sqrt(np.mean(np.square(a - b)))\n",
    "    def MAE(self, a, b):\n",
    "        return np.mean(abs(a-b))\n",
    "    \n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, outputstring, positive, negative): \n",
    "        self.outputstring = outputstring\n",
    "        self.positive = positive\n",
    "        self.negative = negative\n",
    "        self.nodes = []\n",
    "        self.label = None\n",
    "        self.root = False\n",
    "\n",
    "    def LearnDecisionTree(self, examples, attributes, parent_examples, column_values):\n",
    "        self.root = True\n",
    "        self.LearnDecisionTreeAux_(examples, attributes, parent_examples, column_values)\n",
    "\n",
    "    def LearnDecisionTreeAux_(self, examples, attributes, parent_examples, column_values):\n",
    "        same_classification = self.SameClassification(examples)    \n",
    "        \n",
    "        if len(examples.loc[:, examples.columns != self.outputstring]) == 0:\n",
    "            return self.PluralityValue(parent_examples)\n",
    "        elif same_classification is not False:\n",
    "            return same_classification\n",
    "        elif len(attributes) == 0: \n",
    "            return self.PluralityValue(examples)\n",
    "        else:\n",
    "            bestattribute = self.Importance(attributes, examples)\n",
    "            self.label = bestattribute #Seleziono l'attributo migliore\n",
    "            \n",
    "            for value in self.Values1(bestattribute, column_values):\n",
    "                remainingexamples = self.Examples(bestattribute, examples, value)\n",
    "                tree = DecisionTree(self.outputstring, self.positive, self.negative)\n",
    "                attributes_left = self.PopListValue(attributes.copy(), bestattribute)                \n",
    "                subtree = tree.LearnDecisionTreeAux_(remainingexamples.loc[:, remainingexamples.columns != bestattribute], attributes_left, examples, column_values)\n",
    "                self.nodes.append((value, subtree))\n",
    "        return self\n",
    "        \n",
    "    def Importance(self, attributes, examples): \n",
    "        max = -1\n",
    "        ret = None\n",
    "        for a in attributes:\n",
    "            loc = self.Gain(examples, a)\n",
    "            if loc > max:\n",
    "                max = loc\n",
    "                ret = a\n",
    "        return ret\n",
    "        \n",
    "    def B(self, q):\n",
    "        if q == 1 or q == 0:\n",
    "            return 0\n",
    "        return -(q*math.log2(q)+(1-q)*math.log2(1-q))\n",
    "    \n",
    "    def Remainder(self, examples, attribute, p, n):\n",
    "        sum = 0\n",
    "        \n",
    "        for v in self.Values2(attribute, examples):\n",
    "            if type(v) is not str and math.isnan(float(v)):\n",
    "                pk = len(examples.loc[(examples[self.outputstring] == self.positive) & (examples[attribute].isnull())])\n",
    "                nk = len(examples.loc[(examples[self.outputstring] == self.negative) & (examples[attribute].isnull())])\n",
    "            else:\n",
    "                pk = len(examples.loc[(examples[self.outputstring] == self.positive) & (examples[attribute] == v)])\n",
    "                nk = len(examples.loc[(examples[self.outputstring] == self.negative) & ((examples[attribute] == v))])\n",
    "            \n",
    "            partial = (pk+nk)*self.B(pk/(pk+nk))\n",
    "            sum += partial\n",
    "        return (1/(p+n))*sum\n",
    "    \n",
    "    def Gain(self, examples, attribute):\n",
    "        p = len(examples.loc[examples[self.outputstring] == self.positive])\n",
    "        n = len(examples.loc[examples[self.outputstring] == self.negative])\n",
    "        b = self.B(p/(p+n))\n",
    "        r = self.Remainder(examples, attribute, p, n)\n",
    "        return (b-r)\n",
    "        \n",
    "    def PluralityValue(self, parent_examples): \n",
    "        '''Selects the most common ouput value among a set of examples, breaking ties randomly'''\n",
    "        value, max = [], 0\n",
    "        d = self.CreateDictionary(parent_examples)\n",
    "        for key in d.keys():\n",
    "            if d.get(key) > max:\n",
    "                max = d.get(key)\n",
    "                value = []\n",
    "                value.append(key)\n",
    "            elif d.get(key) == max:\n",
    "                '''se ci sono più massimi li metto tutti in una lista dalla quale ne\n",
    "                    selezionerò uno randomicamente\n",
    "                '''\n",
    "                value.append(key)\n",
    "        return rn.choice(value)\n",
    "        \n",
    "    def SameClassification(self, examples): \n",
    "        if (len(examples) == 0):\n",
    "            return False\n",
    "        d = self.CreateDictionary(examples)\n",
    "        if (len(d.keys()) == 1):\n",
    "            return list(d.keys())[0]\n",
    "        return False\n",
    "    def CreateDictionary(self, examples):\n",
    "        examples = examples[self.outputstring].tolist()\n",
    "        d = {}\n",
    "        for i in range(len(examples)):\n",
    "            if d.get(examples[i]) is None:\n",
    "                d[examples[i]] = 1\n",
    "            else:\n",
    "                d[examples[i]] += 1\n",
    "        return d\n",
    "\n",
    "    def Values1(self, attribute, dictionary): \n",
    "        return list(dictionary.get(attribute))\n",
    "    \n",
    "    def Values2(self, attribute, examples):\n",
    "        return examples[attribute].unique()\n",
    "\n",
    "    def Examples(self, attribute, examples, value):\n",
    "        exs = examples.loc[examples[attribute] == value]\n",
    "        return exs\n",
    "    def PopListValue(self, lista, value):\n",
    "        if value not in lista:\n",
    "            return None\n",
    "        lista.remove(value)\n",
    "        return lista \n",
    "    def PrintDecisionTree(self, count):\n",
    "        print(\" \"*count, self.label)\n",
    "        for elem in self.nodes:\n",
    "            if type(elem[1]) is not DecisionTree:\n",
    "                print(\"    \"*(count+1), elem[0], \" --> \", elem[1])\n",
    "            else:\n",
    "                elem[1].PrintDecisionTree(count+1)\n",
    "\n",
    "    def Prediction(self, input):\n",
    "        for i in range(len(self.nodes)):\n",
    "            x = input[self.label].values[0]\n",
    "            if type(self.nodes[i][0]) is not str and math.isnan(float(self.nodes[i][0])):\n",
    "                if type(x) is not str and math.isnan(float(x)):\n",
    "                    if type(self.nodes[i][1]) is DecisionTree:\n",
    "                        return self.nodes[i][1].Prediction(input)\n",
    "                    return self.nodes[i][1]\n",
    "            elif self.nodes[i][0] == x:\n",
    "                if type(self.nodes[i][1]) is DecisionTree:\n",
    "                    return self.nodes[i][1].Prediction(input)\n",
    "                return self.nodes[i][1]\n",
    "        return None\n",
    "\n",
    "class GradientDescent:\n",
    "    def __init__(self, learningrate, epochs, parameters_length, output_string): \n",
    "        self.learningrate = learningrate\n",
    "        self.epochs = epochs\n",
    "        self.parameters_length = parameters_length\n",
    "        self.parameters = None\n",
    "        self.output_string = output_string\n",
    "        self.len_totale = None\n",
    "\n",
    "    def SGD(self, training_set):\n",
    "        \n",
    "        self.parameters = np.ones(self.parameters_length)\n",
    "        input_totale = training_set.loc[:len(training_set), training_set.columns != self.output_string]\n",
    "        output_totale = training_set.loc[:len(training_set), training_set.columns == self.output_string]\n",
    "        self.len_totale = len(training_set)\n",
    "        print(self.len_totale)\n",
    "        error = self.MSE(self.prediction(input_totale), output_totale)\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            g = randrange(len(training_set))\n",
    "            input = training_set.loc[g:g, training_set.columns != self.output_string]\n",
    "            output = training_set.loc[g:g, training_set.columns == self.output_string]\n",
    "            gradient = self.gradient(input, output)\n",
    "            self.SGD_aux(gradient)\n",
    "            \n",
    "            if (not (i%10000)):\n",
    "                #print(\"Parametri: \", self.parameters, \"\\t in epoca: \", i)\n",
    "                #print(\"Epoca: \\t\", i)\n",
    "                print(\"MSE: \", self.MSE(self.prediction(input_totale), output_totale))\n",
    "\n",
    "                #if self.MSE(self.prediction(input_totale), output_totale) < error/2:\n",
    "                #    self.learningrate *= 0.33\n",
    "                #    error = self.MSE(self.prediction(input_totale), output_totale)\n",
    "                #    print(\"Aggiornato learningrate1: \", self.learningrate)\n",
    "                #elif self.MSE(self.prediction(input_totale), output_totale) < 0.95*error:\n",
    "                #    self.learningrate /= 200\n",
    "                #    error = self.MSE(self.prediction(input_totale), output_totale)\n",
    "                #    print(\"Aggiornato learningrate2: \", self.learningrate)\n",
    "                \n",
    "        return self.parameters\n",
    "\n",
    "    def SGD_aux(self, gradient):\n",
    "        for f in range(self.parameters_length):\n",
    "            self.parameters[f] = self.parameters[f]-(self.learningrate*gradient[f][0])\n",
    "\n",
    "    def gradient(self, input, output): \n",
    "        output = np.array(output)\n",
    "        prediction = self.prediction(input)\n",
    "        error = prediction - output\n",
    "        coefficient = input.shape[0]/self.len_totale\n",
    "        return np.dot(coefficient*input.T, error)\n",
    "\n",
    "    def prediction(self, input):\n",
    "        return np.dot(input, self.parameters)\n",
    "\n",
    "    def MSE(self, prediction, output):\n",
    "        output = np.array(output)\n",
    "        return np.mean((output - prediction)**2)\n",
    "    def RMSE(self, prediction, output):\n",
    "        return math.sqrt(np.mean((output - prediction)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2fa37c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1899\n",
      "MSE:  5884.156349861111\n",
      "MSE:  nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[262], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m gd \u001b[38;5;241m=\u001b[39m GradientDescent(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1000000\u001b[39m, dataset_training\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 4\u001b[0m pesi \u001b[38;5;241m=\u001b[39m \u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_training\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(end\u001b[38;5;241m-\u001b[39mstart, pesi)\n",
      "Cell \u001b[0;32mIn[261], line 225\u001b[0m, in \u001b[0;36mGradientDescent.SGD\u001b[0;34m(self, training_set)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m training_set\u001b[38;5;241m.\u001b[39mloc[g:g, training_set\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_string]\n\u001b[1;32m    224\u001b[0m output \u001b[38;5;241m=\u001b[39m training_set\u001b[38;5;241m.\u001b[39mloc[g:g, training_set\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_string]\n\u001b[0;32m--> 225\u001b[0m gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSGD_aux(gradient)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m (i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10000\u001b[39m)):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#print(\"Parametri: \", self.parameters, \"\\t in epoca: \", i)\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#print(\"Epoca: \\t\", i)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[261], line 254\u001b[0m, in \u001b[0;36mGradientDescent.gradient\u001b[0;34m(self, input, output)\u001b[0m\n\u001b[1;32m    252\u001b[0m coefficient \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m#coefficient = input.shape[0]/self.len_totale\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(\u001b[43mcoefficient\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m, error)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/arraylike.py:206\u001b[0m, in \u001b[0;36mOpsMixin.__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__rmul__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rmul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmul\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:7900\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7897\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   7899\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 7900\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_frame_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7901\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:7932\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[0;34m(self, right, func, axis)\u001b[0m\n\u001b[1;32m   7929\u001b[0m right \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(right)\n\u001b[1;32m   7930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(right):\n\u001b[1;32m   7931\u001b[0m     \u001b[38;5;66;03m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[39;00m\n\u001b[0;32m-> 7932\u001b[0m     bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7933\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(bm, axes\u001b[38;5;241m=\u001b[39mbm\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   7935\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, DataFrame):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/managers.py:361\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m obj[b\u001b[38;5;241m.\u001b[39mmgr_locs\u001b[38;5;241m.\u001b[39mindexer]\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[0;32m--> 361\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gd = GradientDescent(1, 1000000, dataset_training.shape[1]-1, 'Weight')\n",
    "\n",
    "start = time.time()\n",
    "pesi = gd.SGD(dataset_training)\n",
    "end = time.time()\n",
    "print(end-start, pesi)\n",
    "\n",
    "#'''sklearn'''\n",
    "#X = dataset_training.loc[:, dataset_training.columns != 'Weight']\n",
    "#Y = dataset_training.loc[:, dataset_training.columns == 'Weight']\n",
    "#\n",
    "#clf = SGDClassifier(max_iter = 1, tol=1e-3)\n",
    "#clf.fit(X, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "21aa53e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.28270931446636066\n",
      "\n",
      "MSE_sklearn:  0.014430769815389873\n",
      "RMSE_sklearn:  0.12012813914895158\n",
      "MAE_sklearn:  0.10230365163587281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_test = dataset_test.loc[:, dataset_test.columns != 'Weight']\n",
    "#Y_effettivo = dataset_test.loc[:, dataset_test.columns == 'Weight']\n",
    "Y_effettivo = np.array(dataset_test['Weight'])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "Y_predetto = np.array(np.matmul(X_test, pesi))\n",
    "map = Map()\n",
    "#print(Y_effettivo)\n",
    "\n",
    "#a = np.mean((Y_predetto - Y_effettivo)**2)\n",
    "#print(\"Errore MSE: \", a)\n",
    "\n",
    "print(\"MAE: \", map.MAE(Y_effettivo, Y_predetto))\n",
    "print(\"\")\n",
    "reg = LinearRegression().fit(dataset_training.loc[:, dataset_training.columns != 'Weight'], dataset_training.loc[:, dataset_training.columns == 'Weight'])\n",
    "scikit_predict = reg.predict(X_test)\n",
    "print(\"MSE_sklearn: \", map.MSE(Y_effettivo, scikit_predict))\n",
    "print(\"RMSE_sklearn: \", map.RMSE(Y_effettivo, scikit_predict))\n",
    "print(\"MAE_sklearn: \", map.MAE(Y_effettivo, scikit_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
